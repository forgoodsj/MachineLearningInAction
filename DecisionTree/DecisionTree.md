* ### DecisionTree 中文译名 决策树

* ### 优点：
> 计算复杂度不高，输出结果易于理解，对中间值的确实不敏感，可以处理不相关特征数据。

* ### 缺点：
> 可能会产生过度匹配问题。

* ### 适用数据范围：
> 数值型和标称型

* ### 工作原理：
> 需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起到决定性作用。
>
> 分类后，如果数据子集内的数据不属于同一类型，则需要重复划分。

* ### 伪代码:
> 创建分支的伪代码行数createBranch()
>
> 检测数据集中的每个子项是否属于统一分类：
>
>    if so return 类标签；
>
>    else
>
>        寻找划分数据集的最好特征
>
>        划分数据集
>
>        创建分支节点
>
>            for 每个划分的子集
>
>                   调用函数createBranch并增加返回结果到分支节点中
>
>        return 分支节点

* ### 若划分数据集时有多个特征，选择哪个特征作为划分的参考属性？
> 原则：将无序的数据变得更加有序。使用信息增益来衡量有序程度。

* ### 信息增益
> 在划分数据集之前之后信息发生的变化成为信息增益。我们可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。




